{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning: Sensor Algorithms\n",
    "\n",
    "This notebook teaches you about different sensor algorithms and data processing techniques. **You'll need to fill in the missing code!**\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Understanding sensor data processing\n",
    "2. Implementing noise filtering\n",
    "3. Implementing clustering algorithms for object detection\n",
    "4. Implementing ray casting for LiDAR simulation\n",
    "5. Sensor fusion techniques\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Read each section carefully\n",
    "- Look for `# TODO:` comments - these indicate where you need to write code\n",
    "- Fill in the `...` placeholders\n",
    "- Run cells as you complete them to test your work\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Understanding of sensors (see [Sensor Tutorial](../tutorials/sensor_tutorial.ipynb))\n",
    "- Understanding of classes (see [Understanding Classes and OOP](../oop_fundamentals/understanding_classes_and_oop.ipynb))\n",
    "- Basic numpy knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../../../src')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Noise Filtering\n",
    "\n",
    "Real sensors have noise. Let's implement filtering algorithms to clean up sensor data.\n",
    "\n",
    "### Moving Average Filter\n",
    "\n",
    "A simple filter that averages the last N measurements.\n",
    "\n",
    "**TODO**: Implement a moving average filter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingAverageFilter:\n",
    "    \"\"\"\n",
    "    Moving average filter for sensor data.\n",
    "\n",
    "    TODO: Fill in the implementation!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size=5):\n",
    "        \"\"\"\n",
    "        Initialize filter.\n",
    "\n",
    "        TODO: Store window_size and initialize buffer\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        # TODO: Initialize buffer to store recent measurements\n",
    "        self.buffer = []\n",
    "\n",
    "    def filter(self, measurement):\n",
    "        \"\"\"\n",
    "        Filter a measurement.\n",
    "\n",
    "        TODO:\n",
    "        1. Add measurement to buffer\n",
    "        2. Keep only last window_size measurements\n",
    "        3. Return average of buffer\n",
    "        \"\"\"\n",
    "        # TODO: Add to buffer\n",
    "        self.buffer.append(...)\n",
    "\n",
    "        # TODO: Keep only last window_size\n",
    "        if len(self.buffer) > ...:\n",
    "            self.buffer = ...  # Keep last window_size elements\n",
    "\n",
    "        # TODO: Return average\n",
    "        return ...  # np.mean(self.buffer)\n",
    "\n",
    "# Test the filter\n",
    "filter_1d = MovingAverageFilter(window_size=5)\n",
    "\n",
    "# Simulate noisy measurements\n",
    "true_value = 10.0\n",
    "noisy_measurements = true_value + np.random.normal(0, 1.0, 20)\n",
    "\n",
    "filtered = [filter_1d.filter(m) for m in noisy_measurements]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(noisy_measurements, 'r.', label='Noisy', alpha=0.5)\n",
    "plt.plot(filtered, 'b-', label='Filtered', linewidth=2)\n",
    "plt.axhline(true_value, 'g--', label='True Value')\n",
    "plt.legend()\n",
    "plt.title('Moving Average Filter')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Measurement')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Noise std: {np.std(noisy_measurements):.3f}\")\n",
    "print(f\"Filtered std: {np.std(filtered[-10:]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clustering for Object Detection\n",
    "\n",
    "Clustering groups nearby points together, which is useful for detecting objects.\n",
    "\n",
    "### DBSCAN-like Simple Clustering\n",
    "\n",
    "**TODO**: Implement a simple distance-based clustering algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClusterer:\n",
    "    \"\"\"\n",
    "    Simple distance-based clustering for point clouds.\n",
    "\n",
    "    TODO: Fill in the implementation!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, distance_threshold=2.0, min_points=3):\n",
    "        \"\"\"\n",
    "        Initialize clusterer.\n",
    "\n",
    "        TODO: Store distance_threshold and min_points\n",
    "        \"\"\"\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.min_points = min_points\n",
    "\n",
    "    def cluster(self, points):\n",
    "        \"\"\"\n",
    "        Cluster points into groups.\n",
    "\n",
    "        TODO: Implement simple clustering:\n",
    "        1. For each unassigned point:\n",
    "           - Find all points within distance_threshold\n",
    "           - If >= min_points, create new cluster\n",
    "           - Assign all nearby points to cluster\n",
    "        2. Return list of clusters (each cluster is array of points)\n",
    "        \"\"\"\n",
    "        if len(points) == 0:\n",
    "            return []\n",
    "\n",
    "        points = np.array(points)\n",
    "        clusters = []\n",
    "        assigned = np.zeros(len(points), dtype=bool)\n",
    "\n",
    "        # TODO: Implement clustering algorithm\n",
    "        for i in range(len(points)):\n",
    "            if assigned[i]:\n",
    "                continue\n",
    "\n",
    "            # TODO: Find nearby points\n",
    "            nearby = ...  # Indices where distance < threshold\n",
    "\n",
    "            # TODO: Check if enough points for cluster\n",
    "            if len(nearby) >= ...:\n",
    "                # Create cluster\n",
    "                cluster_points = ...  # Points in this cluster\n",
    "                clusters.append(cluster_points)\n",
    "                assigned[nearby] = True\n",
    "\n",
    "        return clusters\n",
    "\n",
    "# Test clustering\n",
    "# Create synthetic point cloud with clusters\n",
    "np.random.seed(42)\n",
    "\n",
    "# Cluster 1\n",
    "cluster1 = np.random.randn(10, 2) * 0.5 + [5, 5]\n",
    "# Cluster 2\n",
    "cluster2 = np.random.randn(8, 2) * 0.5 + [15, 10]\n",
    "# Noise points\n",
    "noise = np.random.rand(5, 2) * 20\n",
    "\n",
    "points = np.vstack([cluster1, cluster2, noise])\n",
    "\n",
    "# Cluster\n",
    "clusterer = SimpleClusterer(distance_threshold=2.0, min_points=3)\n",
    "clusters = clusterer.cluster(points)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(clusters)))\n",
    "\n",
    "for idx, cluster in enumerate(clusters):\n",
    "    plt.scatter(cluster[:, 0], cluster[:, 1], c=[colors[idx]], label=f'Cluster {idx+1}', s=50)\n",
    "\n",
    "# Plot unclustered points\n",
    "all_clustered = np.vstack(clusters) if clusters else np.array([]).reshape(0, 2)\n",
    "if len(all_clustered) > 0:\n",
    "    unclustered = points[np.all([np.any(p != all_clustered, axis=1) for p in points], axis=0)]\n",
    "    if len(unclustered) > 0:\n",
    "        plt.scatter(unclustered[:, 0], unclustered[:, 1], c='gray', marker='x', label='Noise', s=50)\n",
    "\n",
    "plt.xlabel('X (m)')\n",
    "plt.ylabel('Y (m)')\n",
    "plt.title(f'Clustering Result: {len(clusters)} clusters found')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Found {len(clusters)} clusters\")\n",
    "for idx, cluster in enumerate(clusters):\n",
    "    print(f\"  Cluster {idx+1}: {len(cluster)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Sensor Fusion\n",
    "\n",
    "Sensor fusion combines data from multiple sensors to get better estimates.\n",
    "\n",
    "### Weighted Average Fusion\n",
    "\n",
    "**TODO**: Implement a simple weighted average fusion for combining sensor measurements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SensorFusion:\n",
    "    \"\"\"\n",
    "    Simple sensor fusion using weighted average.\n",
    "\n",
    "    TODO: Fill in the implementation!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize fusion system.\"\"\"\n",
    "        self.sensor_weights = {}  # Will store weights for each sensor\n",
    "\n",
    "    def set_sensor_weight(self, sensor_name, weight):\n",
    "        \"\"\"\n",
    "        Set weight for a sensor (higher = more trusted).\n",
    "\n",
    "        TODO: Store weight for sensor\n",
    "        \"\"\"\n",
    "        self.sensor_weights[sensor_name] = weight\n",
    "\n",
    "    def fuse_measurements(self, measurements):\n",
    "        \"\"\"\n",
    "        Fuse measurements from multiple sensors.\n",
    "\n",
    "        TODO:\n",
    "        1. Calculate weighted sum: sum(weight * measurement)\n",
    "        2. Calculate sum of weights\n",
    "        3. Return weighted average: weighted_sum / sum_weights\n",
    "\n",
    "        measurements: dict of {sensor_name: measurement_value}\n",
    "        \"\"\"\n",
    "        if len(measurements) == 0:\n",
    "            return None\n",
    "\n",
    "        # TODO: Calculate weighted average\n",
    "        weighted_sum = 0.0\n",
    "        sum_weights = 0.0\n",
    "\n",
    "        for sensor_name, measurement in measurements.items():\n",
    "            self.sensor_weights.get(sensor_name, 1.0)  # Default weight = 1.0\n",
    "            weighted_sum += ...  # weight * measurement\n",
    "            sum_weights += ...  # weight\n",
    "\n",
    "        if sum_weights == 0:\n",
    "            return None\n",
    "\n",
    "        return ...  # weighted_sum / sum_weights\n",
    "\n",
    "# Test fusion\n",
    "fusion = SensorFusion()\n",
    "fusion.set_sensor_weight('lidar', 0.7)  # High trust\n",
    "fusion.set_sensor_weight('camera', 0.3)  # Lower trust\n",
    "\n",
    "# Simulate measurements\n",
    "true_value = 10.0\n",
    "lidar_measurement = true_value + np.random.normal(0, 0.5)  # Less noise\n",
    "camera_measurement = true_value + np.random.normal(0, 1.5)  # More noise\n",
    "\n",
    "measurements = {\n",
    "    'lidar': lidar_measurement,\n",
    "    'camera': camera_measurement\n",
    "}\n",
    "\n",
    "fused = fusion.fuse_measurements(measurements)\n",
    "\n",
    "print(f\"True value: {true_value:.2f}\")\n",
    "print(f\"LiDAR measurement: {lidar_measurement:.2f} (error: {abs(lidar_measurement - true_value):.2f})\")\n",
    "print(f\"Camera measurement: {camera_measurement:.2f} (error: {abs(camera_measurement - true_value):.2f})\")\n",
    "print(f\"Fused measurement: {fused:.2f} (error: {abs(fused - true_value):.2f})\")\n",
    "print(\"\\nFusion reduced error by combining sensors!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned about sensor algorithms:\n",
    "\n",
    "1. **Noise Filtering**: Moving average filter to reduce sensor noise\n",
    "2. **Clustering**: Grouping points to detect objects\n",
    "3. **Sensor Fusion**: Combining multiple sensors for better estimates\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Filtering**: Reduces noise but adds delay\n",
    "- **Clustering**: Helps identify objects in point clouds\n",
    "- **Fusion**: Improves accuracy by combining multiple sources\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different filter window sizes\n",
    "- Experiment with clustering parameters\n",
    "- Implement more advanced fusion algorithms (Kalman filter)\n",
    "- See [Building a Custom Sensor](../sensors/learning_build_sensor.ipynb) for more examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
